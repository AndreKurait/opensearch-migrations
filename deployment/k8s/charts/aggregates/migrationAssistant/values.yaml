conditionalPackageInstalls:
  sharedConfigs: true
  snapshotVolume: true
  migrationConsole: true
  bulkLoader: true
  proxy: true
  kafka: true
  replayer: true
  argoWorkflows: true
  gatekeeper: true
  grafana: false
  prometheus: false
  jaeger: false


shared-configs:
  globalParameters:
    sourceCluster:
      allowRuntimeOverride: true
      object:
        endpoint: "http://elasticsearch-master:9200"
        allowInsecure: true
        authType: "no_auth"
        version: "7.10.2"
    targetCluster:
      allowRuntimeOverride: true
      object:
        endpoint: "https://opensearch-cluster-master:9200"
        allowInsecure: true
        authType: "basic_auth"
        basicAuthUsername: "admin"
        basicAuthPassword: "myStrongPassword123!"
        # Should be in sync with above username/password
        basicAuthHeader: "Basic YWRtaW46bXlTdHJvbmdQYXNzd29yZDEyMyE="
        version: "2.16.0"
    kafkaBrokers:
      allowRuntimeOverride: false
      object:
        brokers: "captured-traffic-kafka-bootstrap.ma.svc:9092"
        kafkaType: "standard"
    snapshot:
      allowRuntimeOverride: true
      object:
        #otelEndpoint: "http://localhost:4317"
        repoPath: "/snapshot"
        snapshotName: "migration-assistant-snapshot"
        snapshotType: "fs"
    metadataMigration:
      allowRuntimeOverride: true
      object:
        minReplicas: 0
        metadataType: "from_snapshot"
        #otelEndpoint: "http://localhost:4317"
        sourceClusterVersion: "ES_7.10"
#    metricsSource:
#      allowRuntimeOverride: false
#      object:
#        endpoint: "http://prometheus:9090"
#        observabilityType: "prometheus"


capture-proxy:
  parameters:
    destinationUri:
      source: otherConfig
      configMapName: "source-cluster"
      configMapKey: "endpoint"
    insecureDestination:
      source: otherConfig
      configMapName: "source-cluster"
      configMapKey: "allowInsecure"
    kafkaConnection:
      source: otherConfig
      configMapName: "kafka-brokers"
      configMapKey: "brokers"


migration-console:
  snapshotVolumeEnabled: true
  snapshotVolumePvc: "snapshot-volume-pvc"


bulk-document-loader:
  snapshotVolumeEnabled: true
  snapshotVolumePvc: "snapshot-volume-pvc"
  parameters:
    snapshotName:
      source: otherConfig
      configMapName: "snapshot"
      configMapKey: "snapshotName"
    targetHost:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "endpoint"
    targetInsecure:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "allowInsecure"
      parameterType: booleanFlag
    targetUsername:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "basicAuthUsername"
    targetPassword:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "basicAuthPassword"


replayer:
  parameters:
    kafkaTrafficBrokers:
      source: otherConfig  # eventually this will become a list from a shared config
      configMapName: "kafka-brokers"
      configMapKey: "brokers"
    targetUri:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "endpoint"
    insecure:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "allowInsecure"
      parameterType: booleanFlag
    authHeaderValue:
      source: otherConfig
      configMapName: "target-cluster"
      configMapKey: "basicAuthHeader"


captured-traffic-kafka-cluster:
  environment: test

  clusterName: captured-traffic

  replicas: 1
  storageType: ephemeral
  storageSize: 100Gi
  storageDeleteClaim: true
  dedicatedController:
    replicas: 1
    storageSize: 10Gi


argo-workflows:
  fullnameOverride: "argo-workflows"

  controller:
    containerSecurityContext:
      runAsNonRoot: true
      allowPrivilegeEscalation: false
    clusterWorkflowTemplates:
      enabled: false
    metricsConfig: # to publish
      enabled: true

  server:
    extraArgs:
      - --auth-mode=server

  serviceAccount:
    create: true
    name: argo-workflows-sa

  singleNamespace: true

  # Extra workflow configuration
  workflow:
    serviceAccount:
      create: true
      name: workflow-restricted-sa


workflowService:
  defaultEnvVars:
    ENV_VAR1: "default-value-1"
    ENV_VAR2: "default-value-2"

  defaultReplicas: 1

  monitorImage: "bitnami/kubectl:latest"

  allowedRepos:
    - "bitnami/"
#    - "k8s.gcr.io/"
#    - "docker.io/library/"


gatekeeper:
  auditInterval: 60
  constraintViolationsLimit: 20
  enableExternalData: true
  audit:
    resources:
      limits:
        cpu: 1000m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi
  controllerManager:
    resources:
      limits:
        cpu: 1000m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi


jaeger:
  allInOne:
    enabled: true
  provisionDataStore:
    cassandra: false
  storage:
    type: memory
  agent:
    enabled: false
  collector:
    enabled: false
  query:
    enabled: false

grafana:
  ## Grafana data sources configuration
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://prometheus-server.prometheus.svc.cluster.local:9090
          isDefault: true
          editable: true
        - name: Jaeger
          type: jaeger
          access: proxy
          url: http://jaeger-query.jaeger.svc.cluster.local:16686
          isDefault: false
          editable: true

  ## Set up the sidecar to import data sources (usually enabled by default)
  sidecar:
    datasources:
      enabled: true
    dashboards:
      enabled: true
      label: grafana_dashboard
