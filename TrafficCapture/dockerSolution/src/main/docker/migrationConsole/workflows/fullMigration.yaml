apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: full-migration
spec:
  serviceAccountName: argo-workflow-executor
  entrypoint: main
  parallelism: 100

  arguments:
    parameters:
      - name: etcd-endpoints
        value: "http://ma-etcd.ma.svc.cluster.local:2379"
      - name: etcd-user
        value: "root"
      - name: etcd-password
        value: "password"
      - name: etcd-image
        value: "migrations/migration_console:latest"
      - name: create-snapshot-template-name
        value: "create-snapshot"


  templates:
    # Main workflow template
    - name: main
      inputs:
        parameters:
          - name: source-migration-configs
            default: "[{\"source\":{\"endpoint\":\"https://sourceA.example.com\",\"auth\":{\"type\":\"basic\",\"username\":\"user\",\"password\":\"pass\"}},\"snapshot-and-migration-configs\":[{\"indices\":[\"index_1\",\"index_2\"],\"existingSnapshot\":{},\"migrations\":[{\"metadata\":{\"mappings\":{\"properties\":{}},\"settings\":{}},\"documentBackfillConfigs\":[{\"indices\":[\"index_1\"]},{\"indices\":[\"index_2\"]}]}]}],\"replayer-config\":{\"batchSize\":1000,\"concurrency\":4}},{\"source\":{\"endpoint\":\"https://sourceB.example.com\",\"auth\":{\"type\":\"basic\",\"username\":\"user\",\"password\":\"pass\"}},\"snapshot-and-migration-configs\":[{\"indices\":[\"index_3\",\"index_4\"],\"existingSnapshot\":{},\"migrations\":[{\"metadata\":{\"mappings\":{\"properties\":{}},\"settings\":{}},\"documentBackfillConfigs\":[{\"indices\":[\"index_3\",\"index_4\"]}]}]}],\"replayer-config\":{\"batchSize\":1000,\"concurrency\":4}}]"
          - name: targets
            value: "[{\"endpoint\":\"https://t1.example.com\"}, {\"endpoint\":\"https://t2.example.com\"}]"
      steps:
        - - name: init
            template: init-etcd-keys
            arguments:
              parameters:
                - name: configurations
                  value: "{{inputs.parameters.source-migration-configs}}"
                - name: targets
                  value: "{{inputs.parameters.targets}}"
                - name: prefix
                  value: "workflow-{{workflow.uid}}"

        - - name: source-pipeline
            template: source-migration-pipeline
            withParam: "{{inputs.parameters.source-migration-configs}}"
            arguments:
              parameters:
                - name: source-migration-config
                  value: "{{item}}"
                - name: targets
                  value: "{{inputs.parameters.targets}}"
                - name: prefix
                  value: "{{steps.init.outputs.parameters.prefix}}"

        - - name: cleanup
            template: cleanup-etcd-keys
            arguments:
              parameters:
                - name: prefix
                  value: "{{steps.init.outputs.parameters.prefix}}"


    - name: init-etcd-keys
      inputs:
        parameters:
          - name: configurations
          - name: targets
          - name: prefix
      outputs:
        parameters:
          - name: prefix
            valueFrom:
              path: /tmp/prefix
          - name: processors-per-target
            valueFrom:
              path: /tmp/processors-per-target
      container:
        image: migrations/migration_console:latest
        imagePullPolicy: Never
        command: [sh, -c]
        args:
          - |
            SOURCE_CONFIG=$(echo '{{inputs.parameters.configurations}}')
            TARGETS_CONFIG=$(echo '{{inputs.parameters.targets}}')
            ls -l /usr/local/bin/
            echo "source config = $SOURCE_CONFIG"
            echo "targets config = $TARGETS_CONFIG"

            # Function to normalize endpoint for use in etcd keys
            # Keeps protocol and port, but normalizes slashes
            normalize_endpoint() {
              echo "$1" | base64
            }

            # Check for duplicate source endpoints
            echo "Checking for duplicate source endpoints..."
            SOURCE_ENDPOINTS=$(echo "$SOURCE_CONFIG" | jq -r '[.[] | .source.endpoint] | unique | length')
            TOTAL_SOURCES=$(echo "$SOURCE_CONFIG" | jq -r 'length')
            
            if [ "$SOURCE_ENDPOINTS" -ne "$TOTAL_SOURCES" ]; then
              echo "Error: Duplicate source endpoints detected" >&2
              echo "$SOURCE_CONFIG" | jq -r '.[] | .source.endpoint' | sort | uniq -d >&2
              exit 1
            fi
            
            # Check for duplicate target endpoints
            echo "Checking for duplicate target endpoints..."
            TARGET_ENDPOINTS=$(echo "$TARGETS_CONFIG" | jq -r '[.[] | .endpoint] | unique | length')
            TOTAL_TARGETS=$(echo "$TARGETS_CONFIG" | jq -r 'length')
            
            if [ "$TARGET_ENDPOINTS" -ne "$TOTAL_TARGETS" ]; then
              echo "Error: Duplicate target endpoints detected" >&2
              echo "$TARGETS_CONFIG" | jq -r '.[] | .endpoint' | sort | uniq -d >&2
              exit 1
            fi
            
            # Check for duplicate snapshot/metadata/backfill configurations within each source
            echo "Checking for duplicate configurations..."
            echo "$SOURCE_CONFIG" | jq -c '.[] | .["snapshot-and-migration-configs"]' | while read -r configs; do
              # Check for duplicate indices in snapshot configs
              UNIQUE_INDICES=$(echo "$configs" | jq -r '[.[] | .indices | sort | join(",")] | unique | length')
              TOTAL_CONFIGS=$(echo "$configs" | jq -r 'length')
              
              if [ "$UNIQUE_INDICES" -ne "$TOTAL_CONFIGS" ]; then
                echo "Error: Duplicate snapshot configurations detected for the same indices" >&2
                exit 1
              fi
              
              # Check for duplicate migrations within each snapshot config
              echo "$configs" | jq -c '.[] | .migrations' | while read -r migrations; do
                UNIQUE_MIGRATIONS=$(echo "$migrations" | jq -r 'map(@json) | unique | length')
                TOTAL_MIGRATIONS=$(echo "$migrations" | jq -r 'length')
                
                if [ "$UNIQUE_MIGRATIONS" -ne "$TOTAL_MIGRATIONS" ]; then
                  echo "Error: Duplicate migration configurations detected" >&2
                  exit 1
                fi
              done
            done
            
            # Calculate the total number of processors
            # Count the total number of migrations across all sources and snapshot configs
            PROCESSOR_COUNT=$(echo "$SOURCE_CONFIG" | jq -r '[.[] | .["snapshot-and-migration-configs"][] | .migrations | length] | add')
            echo "Total processor count: $PROCESSOR_COUNT"
            
            echo "{{inputs.parameters.prefix}}" > /tmp/prefix
            export ETCDCTL_API=3
            
            # Run etcdctl with configured endpoints and authentication
            etcdctl_cmd="etcdctl --endpoints={{workflow.parameters.etcd-endpoints}} --user {{workflow.parameters.etcd-user}}:{{workflow.parameters.etcd-password}}"
            
            # Store the workflow prefix in etcd for future reference
            $etcdctl_cmd put /{{inputs.parameters.prefix}}/workflow/info/prefix "{{inputs.parameters.prefix}}"
            $etcdctl_cmd put /{{inputs.parameters.prefix}}/workflow/info/started "$(date +%s)"
            
            # Initialize target latches
            echo "$TARGETS_CONFIG" | jq -c '.[]' | while read -r target_json; do
              TARGET_ENDPOINT=$(echo "$target_json" | jq -r '.endpoint')
              NORMALIZED_TARGET=$(normalize_endpoint "$TARGET_ENDPOINT")
              
              # Initialize the latch with processor count
              $etcdctl_cmd put /{{inputs.parameters.prefix}}/workflow/targets/$NORMALIZED_TARGET/endpoint "$TARGET_ENDPOINT"
              $etcdctl_cmd put /{{inputs.parameters.prefix}}/workflow/targets/$NORMALIZED_TARGET/latch "$PROCESSOR_COUNT"
              
              echo "Target $TARGET_ENDPOINT ($NORMALIZED_TARGET) latch initialized with count $PROCESSOR_COUNT"
            done
            
            # Output the processor count per target for workflow output
            echo "{\"processor_count\": $PROCESSOR_COUNT}" > /tmp/processors-per-target
            
            echo "Etcd keys initialized with prefix: {{inputs.parameters.prefix}}"


    # Unroll snapshotting and their dependent steps
    - name: source-migration-pipeline
      inputs:
        parameters:
          - name: source-migration-config
          - name: targets
          - name: prefix
      steps:
        - - name: snapshot-pipeline
            template: snapshot-pipeline
            withParam: "{{=fromJSON(inputs.parameters['source-migration-config'])['snapshot-and-migration-configs']}}"
            arguments:
              parameters:
                - name: source-config
                  value: "{{=fromJSON(inputs.parameters['source-migration-config'])['source']}}"
                - name: snapshot-and-migration-config
                  value: "{{item}}"
                - name: targets
                  value: "{{inputs.parameters.targets}}"
                - name: process-name
                  value: "{{=toBase64(fromJSON(inputs.parameters['source-migration-config'])['source']['endpoint'])}}"
                  #"\"snapshot-\" + fromJSON(inputs.parameters['source-config']).endpoint.replace(/\\//g, '_') + \"-\" + workflow.uid"
                  #value: "\"snapshot-\" + fromJSON(inputs.parameters['source-config']).endpoint.replace(/\\//g, '_') + \"-\" + workflow.uid"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

    - name: snapshot-pipeline
      inputs:
        parameters:
          - name: source-config
          - name: snapshot-and-migration-config
          - name: targets
          - name: process-name
          - name: prefix
      steps:
        - - name: create-or-get-snapshot
            template: create-or-get-snapshot
            arguments:
              parameters:
                - name: source-config
                  value: "{{inputs.parameters.source-config}}"
                - name: snapshot-and-migration-config
                  value: "{{inputs.parameters.snapshot-and-migration-config}}"
        - - name: snapshot-to-target-pipeline
            template: snapshot-to-target-pipeline
            withParam: "{{inputs.parameters.targets}}"
            arguments:
              parameters:
                - name: source-config
                  value: "{{inputs.parameters.source-config}}"
                - name: snapshot-config
                  value: "{{steps.create-or-get-snapshot.outputs.parameters.snapshot-config}}"
                - name: migration-configs
                  value: "{{=fromJSON(inputs.parameters['snapshot-and-migration-config'])['migrations']}}"
                - name: target
                  value: "{{item}}"
                - name: process-name
                  value: "{{inputs.parameters.process-name}}::{{=toBase64(toJSON(item))}}"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

    - name: create-or-get-snapshot
      inputs:
        parameters:
          - name: source-config
          - name: snapshot-and-migration-config
      outputs:
        parameters:
          - name: snapshot-config
            valueFrom:
              expression: "toJSON(fromJSON(inputs.parameters['snapshot-and-migration-config'])['existingSnapshot'])"
      steps: [[]]

    - name: snapshot-to-target-pipeline
      inputs:
        parameters:
          - name: source-config
          - name: snapshot-config
          - name: migration-configs
          - name: target
          - name: process-name
          - name: prefix
      steps:
        - - name: migrate-from-snapshot-pipeline
            template: migrate-from-snapshot-pipeline
            withParam: "{{inputs.parameters.migration-configs}}"
            arguments:
              parameters:
                - name: source-config
                  value: "{{inputs.parameters.source-config}}"
                - name: snapshot-config
                  value: "{{inputs.parameters.snapshot-config}}"
                - name: migration-config
                  value: "{{item}}"
                - name: target
                  value: "{{inputs.parameters.target}}"
                - name: process-name
                  value: "{{inputs.parameters.process-name}}::{{=toBase64(toJSON(item))}}"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

    - name: migrate-from-snapshot-pipeline
      inputs:
        parameters:
          - name: source-config
          - name: snapshot-config
          - name: migration-config
          - name: target
          - name: process-name
          - name: prefix
      steps:
        - - name: migrate-metadata
            template: migrate-metadata
#            when: "{{=fromJSON(inputs.parameters['migration-config'])['metadata'] != nil}}"
            arguments:
              parameters:
                - name: source-config
                  value: "{{inputs.parameters.source-config}}"
                - name: snapshot-config
                  value: "{{inputs.parameters.snapshot-config}}"
                - name: migration-config
                  value: "{{fromJSON(inputs.parameters['migration-config'])['metadata']}}"
                - name: target
                  value: "{{inputs.parameters.target}}"
        - - name: bulk-load-documents
            template: bulk-load-documents
            withParam: "{{=fromJSON(inputs.parameters['migration-config'])['documentBackfillConfigs']}}"
            arguments:
              parameters:
                - name: snapshot-config
                  value: "{{inputs.parameters.snapshot-config}}"
                - name: rfs-config
                  value: "{{item}}"
                - name: target
                  value: "{{inputs.parameters.target}}"
        # Check target readiness after processing and bump it to the next phase if ready
        - - name: check-for-target-processing-completion
            template: reduce-target-when-ready
            arguments:
              parameters:
                - name: source
                  value: "{{inputs.parameters.source-config}}"
                - name: processor
                  value: "{{inputs.parameters.process-name}}"
                - name: target
                  value: "{{inputs.parameters.target}}"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

    - name: migrate-metadata
      inputs:
        parameters:
          - name: source-config
          - name: snapshot-config
          - name: migration-config
          - name: target
      container:
        image: migrations/migration_console:latest
        imagePullPolicy: IfNotPresent
        command: [ echo ]
        args: [ "metadata migrate" ]

    - name: bulk-load-documents
      inputs:
        parameters:
          - name: snapshot-config
          - name: rfs-config
          - name: target
      container:
        image: migrations/migration_console:latest
        imagePullPolicy: IfNotPresent
        command: [ echo ]
        args: [ "backfill" ]

    # Do target processing after waiting for all other work (processors) to the target to complete
    - name: reduce-target-when-ready
      inputs:
        parameters:
          - name: source
          - name: processor
          - name: target
          - name: prefix
      steps:
        - - name: target-processed-latch
            template: target-processed-latch
            arguments:
              parameters:
                - name: source
                  value: "{{inputs.parameters.source}}"
                - name: processor
                  value: "{{inputs.parameters.processor}}"
                - name: target
                  value: "{{inputs.parameters.target}}"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

        - - name: targets-all-processed-fan-in
            template: reduce-processors-for-target
            when: "{{steps.target-processed-latch.outputs.parameters.should-finalize}} == true"
            arguments:
              parameters:
                - name: target
                  value: "{{inputs.parameters.target}}"
                - name: prefix
                  value: "{{inputs.parameters.prefix}}"

    # Check target processors progress and determine if all the work in this stage
    # for a target has been completed
    - name: target-processed-latch
      inputs:
        parameters:
          - name: source
          - name: processor
          - name: target
          - name: prefix
      outputs:
        parameters:
          - name: should-finalize
            valueFrom:
              path: /tmp/should-finalize
      script:
        image: "{{workflow.parameters.etcd-image}}"
        imagePullPolicy: Never
        command: [sh]
        source: |
          SOURCE_CONFIG=$(echo '{{inputs.parameters.source}}')
          PROCESSOR_ID="{{inputs.parameters.processor}}"
          TARGET_JSON=$(echo '{{inputs.parameters.target}}')
          ETCD_ENDPOINT={{workflow.parameters.etcd-endpoints}}
          PREFIX="{{inputs.parameters.prefix}}"
          
          normalize_endpoint() {
            echo "$1" | base64
          }
          
          TARGET_ENDPOINT=$(echo "$TARGET_JSON" | jq -r '.endpoint')
          NORMALIZED_TARGET=$(normalize_endpoint "$TARGET_ENDPOINT")
          
          SOURCE_ENDPOINT=$(echo "$SOURCE_CONFIG" | jq -r '.endpoint')
          NORMALIZED_SOURCE=$(normalize_endpoint "$SOURCE_ENDPOINT")
          
          USERNAME={{workflow.parameters.etcd-user}}
          PASSWORD={{workflow.parameters.etcd-password}}
          LATCH_KEY_NAME=/$PREFIX/workflow/targets/$NORMALIZED_TARGET/latch
          
          FRIENDLY_NAME="${NORMALIZED_TARGET}-${PROCESSOR_ID}"
          
          export ETCDCTL_API=3
          
          # Run etcdctl with configured endpoints
          etcdctl_cmd="etcdctl --endpoints=$ETCD_ENDPOINT --user $USERNAME:$PASSWORD"
          
          # Record this processor as finished
          $etcdctl_cmd put /$PREFIX/workflow/targets/$NORMALIZED_TARGET/finishedSubFlows/$FRIENDLY_NAME "completed"
  
          execute_transaction() {
          local current_value="$1"
          local next_value="$2"
          
          # be very mindful of the empty lines in the file being sent to the transaction command!
          echo "LATCH_KEY_NAME=$LATCH_KEY_NAME"
          echo "current_value=$current_value"
          echo "next_value=$next_value"
          echo "etcdctl_cmd=$etcdctl_cmd"
          
          $etcdctl_cmd txn  --write-out=json << EOF | jq -e '.succeeded == true'
          val("$LATCH_KEY_NAME") = "$current_value"
          
          put $LATCH_KEY_NAME "$next_value"
                      
          
          EOF
          }

          # Transaction retry loop
          while true; do
            CURRENT_COUNT=$($etcdctl_cmd get  $LATCH_KEY_NAME --print-value-only)
            NEW_COUNT=$((CURRENT_COUNT - 1))
            if execute_transaction "$CURRENT_COUNT" "$NEW_COUNT"; then
              echo "Transaction succeeded"
              break
            else
              echo "Transaction failed, retrying..."
              sleep 0.5
            fi
          done
          
          # Default: don't finalize yet
          SHOULD_FINALIZE="false"
          
          # Check if latch has reached zero
          if [ "$NEW_COUNT" -eq 0 ]; then
            echo "All processors for target $TARGET_ENDPOINT have completed" >&2
            SHOULD_FINALIZE="true"
          else
            echo "Target $TARGET_ENDPOINT still has $NEW_COUNT processors pending" >&2
          fi
          
          # Output just the boolean value to stdout for the result
          echo $SHOULD_FINALIZE > /tmp/should-finalize
          echo $SHOULD_FINALIZE

    # This is where we'd start running live-replay
    - name: reduce-processors-for-target
      inputs:
        parameters:
          - name: target
          - name: prefix
      container:
        image: "{{workflow.parameters.etcd-image}}"
        imagePullPolicy: Never
        command: [sh, -c] # dummy implementation that preserves some stats about the work that was done
        args:
          - |
            echo "reduce-processors-for-target"

    - name: cleanup-etcd-keys
      inputs:
        parameters:
          - name: prefix
      container:
        image: "{{workflow.parameters.etcd-image}}"
        imagePullPolicy: Never
        command: [sh, -c]
        args:
          - |
            export ETCDCTL_API=3
            etcdctl_cmd="etcdctl --endpoints={{workflow.parameters.etcd-endpoints}} --user {{workflow.parameters.etcd-user}}:{{workflow.parameters.etcd-password}}"
            
            PREFIX="{{inputs.parameters.prefix}}"
            echo "===== CLEANING UP ETCD KEYS FOR PREFIX $PREFIX ====="
            
            # Record workflow completion time
            $etcdctl_cmd put /$PREFIX/workflow/info/completed "$(date +%s)"
            STARTED=$($etcdctl_cmd get /$PREFIX/workflow/info/started --print-value-only)
            COMPLETED=$(date +%s)
            DURATION=$((COMPLETED - STARTED))
            
            echo "Workflow completed in $DURATION seconds"
            
            # Get workflow stats for logging purposes
            echo "Workflow completion stats:"
            
            # Keep statistics in a separate key that will persist
            STATS_KEY="workflow-stats/runs/$PREFIX"
            
            # Save summarized workflow stats to a persistent key
            $etcdctl_cmd put /$STATS_KEY/started "$STARTED"
            $etcdctl_cmd put /$STATS_KEY/completed "$COMPLETED"
            $etcdctl_cmd put /$STATS_KEY/duration "$DURATION"
            
            # For each target, save its finalized status and completed processors
            for TARGET_KEY in $($etcdctl_cmd get /$PREFIX/workflow/targets/ --prefix --keys-only | grep "/latch$" | sort); do
              TARGET_PATH=$(echo "$TARGET_KEY" | sed "s|/$PREFIX/workflow/targets/||" | sed "s|/latch$||")
              TARGET_ENDPOINT=$($etcdctl_cmd get /$PREFIX/workflow/targets/$TARGET_PATH/endpoint --print-value-only)
              LATCH_VALUE=$($etcdctl_cmd get $TARGET_KEY --print-value-only)
              
              # Save the target stats
              $etcdctl_cmd put /$STATS_KEY/targets/$TARGET_PATH/endpoint "$TARGET_ENDPOINT"
              $etcdctl_cmd put /$STATS_KEY/targets/$TARGET_PATH/final_latch_value "$LATCH_VALUE"
              
              # Save the list of completed processor chains
              COMPLETED_PROCESSORS=$($etcdctl_cmd get /$PREFIX/workflow/targets/$TARGET_PATH/finishedSubFlows/ --prefix --keys-only | wc -l)
              $etcdctl_cmd put /$STATS_KEY/targets/$TARGET_PATH/completed_processors "$COMPLETED_PROCESSORS"
              
              # Save the list of processor chain names
              PROCESSOR_CHAINS=$($etcdctl_cmd get /$PREFIX/workflow/targets/$TARGET_PATH/finishedSubFlows/ --prefix --keys-only | sort | tr '\n' ',' | sed 's/,$//')
              $etcdctl_cmd put /$STATS_KEY/targets/$TARGET_PATH/processor_chains "$PROCESSOR_CHAINS"
              
              echo "- Target $TARGET_ENDPOINT: Latch=$LATCH_VALUE, Completed Processors=$COMPLETED_PROCESSORS"
            done
            
            # Delete all workflow keys for this run (but keep the stats)
            echo "Deleting all workflow keys with prefix: /$PREFIX/workflow/"
            $etcdctl_cmd del /$PREFIX/workflow/ --prefix
            
            echo "Cleanup complete. Workflow stats preserved under /$STATS_KEY/"
